---
title: "Evaluation de la richesse floristique communale potentielle en Bretagne"
author: "OFB Bretagne - CBN de Brest - OEB"
date: "`r format(Sys.time(), 'Le %d/%m/%Y')`"
output:
  bookdown::html_document2:
    number_sections: yes
    global_numbering: yes
    toc: yes
    toc_float:
      toc_collapsed: yes
      toc_depth: 2
    code_folding: hide
params:
  nb_obs_simu: 20000
  nb_obs_mini: 200
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{css, echo=FALSE}
p.caption {
    font-size: 0.9em;
    font-style: italic;
    color: grey;
    margin-right: 10%;
    margin-left: 10%;  
    text-align: justify;
}
```

# Objectif

Le présent document vise à explorer si les données présentes dans la base du CBN Brest, couplées avec la "Carte des Grands Types de Végétation" (CGTV), permettent d'estimer la richesse potentielle en espèces de chaque commune. 

La principale difficulté réside dans la grande variabilité intercommunale d'effort de prospection.

Par richesse potentielle, on entend le nombre d'espèces qui seraient répertoriées présentes sur la commune si elle était très bien prospectée.

# Approche analytique

## Le jeu de données

Le jeu de données fourni est une table avec une ligne par commune bretonne et les colonnes suivantes :

-	cd_insee : code insee de la commune
-	nb_obs : nombre d’observation floristique dans la commune
-	nb_esp : nombre d’espèces observées actuellement dans la commune
-	nb_station : non utilisé 
-	Shape area : superficie de la commune
-	Shannon : indice de shannon calculé à partir de la CGTV : diversité relative des milieux naturels et semi-naturels
-	Hémérobie : taux d’hémérobie calculé à partir de la CGTV : Impact de l'influence humaine sur les végétations
-	nb_gtm : nombre de grand types de milieu dans la commune, y compris les milieux non naturels ou semi naturels. Des milieux non naturels peuvent amener de nouveaux cortèges d’espèces (murs…)

Il a été produit par le CBN en croisant ses données de relevés floristiques et les informations géographiques sur le découpage communal et la CGTV.  

## Analyses

L'approche comprend deux étapes :

- Modélisation le nombre d'espèces recensées dans chaque commune en fonction de l'effort de prospection (évalué à travers le nombre d'observations floristiques) et de variables connues pour influencer la richesse. Cette première phase est itérative pour obtenir un modèle qui soit à la fois satisfaisant (examen du r², des coefficients et des graphiques de diagnostic) et le plus simple possible.

- Application du modèle afin de prédire, pour chaque commune, le nombre d'espèces qui y serait observé si elle était bien prospectée. Pour le présent test, nous avons choisi un effort de prospection de n_obs = `r params$nb_obs_simu` observations.


# Chargement des données et packages

On charge les librairies R nécessaires, ainsi que les données. Quelques variables sont renommées pour respecter les règles de nommage et être plus explicites.

```{r}
library(tidyverse)
library(COGiter)
library(corrplot)
library(PerformanceAnalytics)
library(mapview)

data <- readxl::read_xlsx("../raw_data/communes_cgtv_variables.xlsx") %>% 
  select(comm_id = fid,
         comm_insee = cd_insee,
         nb_esp,
         comm_surf = shape_area,
         nb_obs,
         gtm_shannon = shannon,
         gtm_heme = hemerobie,
         gtm_nat = richesse,
         gtm_tot = nb_gtm
         )

toutes_communes_var_quant <- data %>% 
  select(-comm_id) %>% 
  column_to_rownames("comm_insee")
```

# Examen des variables

Avant de commencer la modélisation de `nb_esp`, il est essentiel d'examiner graphiquement les variables disponibles :

- Distributions (histogrammes) car on aime bien les cloches.
- Nuages de points par paires de variables afin d'identifier de potentielles redondances ou des relations non linéaires entre les variables explicatives et `nb_esp`. 

## Variables brutes

La variable que l'on cherche à prédire, `nb_esp`, varie de `r min(data$nb_esp)` à `r max(data$nb_esp)` espèces, pour un effort de prospection entre `r min(data$nb_obs)` à `r max(data$nb_obs) %>% format(big.mark = " ", scientific = FALSE)` relevés par commune.

```{r, fig.cap = "Corrélation entre le nombre d'espèces recensées dans les communes et les variables explicatives. Les histogrammes sont sur la diagonale. Les nuages bivariés sont en-dessous, les coefficients de corrélation de Pearson et la significativité de la relation au-dessus."}
chart.Correlation(toutes_communes_var_quant,
                  histogram = TRUE,
                  pch = 19)
```

Il apparaît que les distributions des surfaces communales `comm_surf` et du nombre d'observations `nb_obs` sont très asymétriques donc on leur applique une transformation logarithmique.

Les variables `gtm_nat` et `gtm_tot` sont très fortement liées $\Rightarrow$ redondance. On ne conserve que `gtm_tot`.

En bivarié, le nombre d'espèces observées `nb_esp` est avant tout lié à l'effort de prospection `nb_obs`. Viennent ensuite les variables dérivées des GTM puis la surface.

## Après tri et transformations

```{r}
toutes_communes_var_quant <- toutes_communes_var_quant %>% 
  mutate(comm_surf = log10(comm_surf),
         nb_obs = log10(nb_obs)) %>% 
  select(-gtm_nat)
```


```{r}
sel_communes_var_quant <- toutes_communes_var_quant %>% 
  filter(nb_obs > log10(params$nb_obs_mini))

communes_ecartees_pour_insuffisance_de_donnees <- setdiff(rownames(toutes_communes_var_quant), rownames(sel_communes_var_quant))
```

>Nombre de communes écartées car ne disposant pas de `r params$nb_obs_mini` observations : `r nrow(toutes_communes_var_quant) - nrow(sel_communes_var_quant)`

```{r, fig.cap = "Corrélation entre le nombre d'espèces recensées dans les communes et les variables explicatives triées et transformées, après mise à l'écart des communes insuffisamment prospectées. Les histogrammes sont sur la diagonale. Les nuages bivariés sont en-dessous, les coefficients de corrélation de Pearson et la significativité de la relation au-dessus."}
chart.Correlation(sel_communes_var_quant,
                  histogram = TRUE,
                  pch = 19)
```

# Analyse de la richesse

## Analyse préliminaire

Comme la relation bivariée entre `nb_esp` et `nb_obs` est curvi-linéaire, on introduit un terme quadratique `nb_obs²`.

Le modèle prend donc la forme :

$nb_esp = a.log_{10}(nb_{obs}) + b.(log_{10}(nb_{obs}))² + c.log_{10}(Surf_{comm}) + d.Shannon_{gtm} + e.Heme_{gtm}) + f.Tot_{gtm} + g$

```{r}
modele <- lm(nb_esp ~ nb_obs + I(nb_obs^2) + comm_surf + gtm_shannon + gtm_heme + gtm_tot,
             data = sel_communes_var_quant)
```

### Résumé du modèle

```{r}
summary(modele)
```

**Interprétation rapide**

Le coefficient de détermination ajusté du modèle est `r summary(modele)$adj.r.squared %>% round(3)`, ce qui signifie que `r 100 * summary(modele)$adj.r.squared %>% round(3)`% de la variabilité de `nb_esp` est statistiquement expliqué par les variables explicatives. 

Au seuil de 5%, tous les coefficients sont significativement non nuls à l'exception de la surface communale, donc le choix initial des variables semble pertinent.


### Graphiques de diagnostic

On examine une série standard de nuages de point mettant en jeu les résidus (valeur prédite - valeur observée = erreur du modèle), les valeurs prédites et la distance de Cook (influence de l'observation sur la construction du modèle). La validation du modèle requiert les conditions ci-dessous.

- *Residuals vs fitted* et *Scale-location* (Un point par commune) $\Rightarrow$ **Absence de lien**.
- *Diagramme quantile-quantile des résidus* (Un point par pourcentile) $\Rightarrow$ **Points sur la ligne**, ce qui signifie que la distribution des résidus est gaussienne.
- *Residuals vs Leverage* (Un point par commune) $\Rightarrow$ **Absence de lien** ; ce graphique peut aussi permettre l'identification de communes exagérément influentes.


```{r}
plot(modele)
```

Sur les graphiques de diagnostic ci-dessus, on voit que pour certaines communes :

- les résidus sont très importants  (= forte erreur du modèle, cas de communes où la richesse est sur-ou sous-estimée d'une centaine d'espèces)
- le "bras de levier" (distance de Cook) est très fort, ce qui indique une influence majeure (exagérée) sur le modèle

## Suppression des communes qui ne rentrent pas dans le schéma général

Ici on cherche une règle générale qui s'appliquerait à l'ensemble des communes de la région. Il n'est donc pas dérangeant d'écarter des observations "atypiques".

### Identification de ces communes

On utilise une régle "à la hache" consistant à écater les observations dont la distance de Cook excède $4/n$, $n$ étant le nombre d'observations ([ref](https://fr.wikipedia.org/wiki/Distance_de_Cook)).

```{r}
dist_cook <- cooks.distance(modele) %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  set_names(c("comm_insee", "cooks_distance")) %>% 
  mutate(quatre_sur_n = 4 / n(),
         garder = cooks_distance < quatre_sur_n)

communes_a_conserver <- dist_cook %>% 
  filter(garder) %>% 
  pull(comm_insee)

communes_ecartees_pour_cook <- setdiff(dist_cook$comm_insee,
                                       communes_a_conserver)
```

### Carte des communes écartées

```{r, fig.cap = "Carte des communes écartées du jeu de données pour construire le modèle sur la base de la distance de Cook."}
communes_bzh <- COGiter::communes_geo %>% 
  mutate(dept = str_sub(DEPCOM, 1, 2)) %>% 
  filter(dept %in% c("22", "29", "35", "56"))

carte <- mapview(communes_bzh %>% filter(!(DEPCOM %in% communes_a_conserver)))

carte@map
```

Il y a manifestement un effet géographique sur cette sélection : les communes écartées sont concentrées sur certains secteurs. Il manque peut-être une ou des variables explicatives.


### Modèle sans ces communes

```{r}
sel_communes_var_quant_propre <- sel_communes_var_quant %>% 
  filter(rownames(sel_communes_var_quant) %in% communes_a_conserver)
```

```{r}
modele <- lm(nb_esp ~ nb_obs + I(nb_obs^2) + comm_surf + gtm_shannon + gtm_heme + gtm_tot,
             data = sel_communes_var_quant_propre)
```

```{r}
summary(modele)
plot(modele)
```

Les graphiques sont nettement plus satisfaisants.

# Modèle retenu

En dernière étape, on essaye de simplifier le modèle en éliminant les variables qui ne contribuent pas à l'améliorer, par une méthode "pas-à-pas" basée sur le critère d'Akaïke.

## Elagage

```{r, echo = FALSE, include=FALSE}
modele_final <- MASS::stepAIC(modele)
```


```{r}
summary(modele_final)
```

On voit que la superficie de la commune a été écartée des variables explicatives.

```{r}
plot(modele_final)
```

On a toujours quelques observations à forte influence mais les trois autres graphiques sont Ok.

## Relation richesse observée - richesse prédite

Le relation est étroite entre la richesse observée et la richesse prédite. La droite de régression se confond avec la droite identité d'équation $y=x$, ce qui indique un bon ajustement sur l'ensemble de la gamme de richesses.

```{r, fig.cap = paste0("Nuage de point de la richesse observée en fonction de la richesse prédite (n = ", nrow(sel_communes_var_quant_propre), "). Chaque point représente une commune.")}
test <- modele_final$fitted.values %>% 
  cbind(modele_final$model) %>% 
  rename(nb_esp_pred = 1)

ggplot(data = test,
       aes(x = nb_esp_pred,
           y = nb_esp)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Richesse prédite",
       y = "Richesse observée")
```

# Richesse potentielle des communes

## Calcul

On utilise le modèle final pour prédire ce que serait la richesse observée dans chaque commune si elle disposait de `r params$nb_obs_simu` observations.

>NB Au stade de la prédition, les communes qui avaient été écartées pour caler le modèle sont réintégrées au jeu de données.

```{r}
new_data <- toutes_communes_var_quant %>% 
  mutate(nb_obs = log10(params$nb_obs_simu)) # car le nb_obs dans le modèle est en log

prediction <- predict(modele, newdata = new_data) %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  set_names(c("comm_insee", "richesse_pot"))
```

```{r}
prediction %>%
  downloadthis::download_this(
    output_name = "richesse_potentielle",
    output_extension = ".xlsx",
    button_label = "Télécharger en Excel",
    button_type = "success",
    has_icon = TRUE,
    icon = "fa fa-save",
    csv2 = TRUE,
  )
```


## Cartographie

Le modèle prédit des diversités maximales sur le littoral, en particulier Sud et Ouest.

```{r}
donnees_carte <- communes_bzh %>% 
  left_join(y = prediction,
            by = c("DEPCOM" = "comm_insee"))
```


```{r, fig.cap = paste0("Cartographie de la richesse potentielle communale estimée pour n=", params$nb_obs_simu, " observations.")}
carte <- mapview(donnees_carte,
                 zcol = "richesse_pot")

carte@map
```

## Distribution

```{r}
richesse_mediane <- median(prediction$richesse_pot)
```

La richesse communale potentielle médiane, estimée pour un effort de prospection de `r params$nb_obs_simu` observations, est de `r round(richesse_mediane)` espèces.

```{r, fig.cap="Distribution des richesses potentielles prédites. La ligne verticale indique la médiane."}
ggplot(data = prediction,
       aes(x = richesse_pot)) +
  geom_histogram(fill = "darkgreen") +
  labs(x = "Richesse communale potentielle",
       y = "Nombre de communes") +
  geom_vline(xintercept = richesse_mediane,
             linetype = "dashed")
```

## Effet de l'effort de prospection

On peut s'interroger sur l'effet du nombre d'observations retenu (ci-dessus fixé à `r params$nb_obs_simu`) sur la richesse potentielle estimée.

```{r}
nb_obs_seq <- c(1e2, 3e2, 1e3, 3e3, 1e4, 18000, 3e4, 5e4, 7e4, 1e5)
```


Pour répondre à cette question, on fait tourner le modèle, en prédiction, sur l'ensemble des communes pour des efforts de prospection variant de `r min(nb_obs_seq)` à `r max(nb_obs_seq) %>% format(big.mark = " ", scientific = FALSE)` observations. On calcule ensuite, pour chaque nombre d'observations, la richesse communale potentielle médiane.

```{r}
richesse_pot_mediane <- data.frame()

for(n_obs_simu in nb_obs_seq)
  
{
  
new_data <- toutes_communes_var_quant %>% 
  mutate(nb_obs = log10(n_obs_simu)) # car le nb_obs dans le modèle est en log

prediction <- predict(modele, newdata = new_data) %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  set_names(c("comm_insee", "richesse_pot"))

richesse_pot_med <- data.frame(richesse_pot = median(prediction$richesse_pot),
                               n_obs_simu)
                               
richesse_pot_mediane <- richesse_pot_mediane %>% 
  rbind(richesse_pot_med)

}
```

```{r, fig.cap = "Effet de l'effort de prospection sur la richesse communale potentielle médiane. L'intersection des lignes pointillées indique les paramètres retenus pour l'ensemble de l'étude."}
ggplot(data = richesse_pot_mediane,
       aes(x = n_obs_simu,
           y = richesse_pot)) +
  geom_point(col = "darkgreen",
             size = 3) +
#  geom_smooth(se = FALSE) +
  geom_line(col = "darkgreen") +
  scale_y_continuous(limits = c(0, NA)) +
  scale_x_continuous(breaks = seq(0, 100000, 10000),
                     labels = function(x) format(x, big.mark = " ", scientific = FALSE)) +
  labs(x = "Nombre d'observations",
       y = "Richesse communale potentielle médiane") +
  geom_hline(yintercept = richesse_mediane,
             linetype = "dashed",
             col = "red") +
  geom_vline(xintercept = params$nb_obs_simu,
             linetype = "dashed",
             col = "red") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```

# Profil des communes écartées

Certaines des communes ont été écartées car elles n'ont pas été suffisamment prospectées (n = `r length(communes_ecartees_pour_insuffisance_de_donnees)`) et d'autres car elles influençaient exagérément le modèle (n = `r length(communes_ecartees_pour_cook)`).

On peut comparer les variables entre les communes conservées dans les analyses et ces deux lots de communes.

```{r}
comparaison_conservees_ecartees <- data %>% 
  mutate(ecartee = case_when(
    comm_insee %in% communes_ecartees_pour_cook ~ "Trop influente",
    comm_insee %in% communes_ecartees_pour_insuffisance_de_donnees ~ "Données insuffisantes",
    TRUE ~ "Conservée")
    )

comparaison_conservees_ecartees <- comparaison_conservees_ecartees %>% 
  select(-comm_id) %>% 
  pivot_longer(nb_esp:gtm_tot,
               names_to = "variable",
               values_to = "valeur")
```


```{r, fig.width = 8, fig.height = 8, fig.cap = "Comparaison de la distribution des variables (histogramme) entre les communes selon qu'elles sont écartées ou conservées."}
ggplot(data = comparaison_conservees_ecartees,
       aes(x = valeur,
           fill = ecartee)) +
  geom_histogram(alpha = 0.5) +
  facet_wrap(~variable,
             scales = "free") +
  labs(x = "Valeur",
       y = "Nombre de communes",
       fill = "Commune")
```

Même type de graphique mais en densités. Comme la surface sous chaque courbe est 1, les communes écartées, moins nombreuses que celles qui sont conservées, apparaissent plus clairement.

```{r, fig.width = 8, fig.height = 8, fig.cap = "Comparaison de la distribution des variables (diagramme de densité) entre les communes selon qu'elles sont écartées ou conservées."}
ggplot(data = comparaison_conservees_ecartees,
       aes(x = valeur,
           fill = ecartee)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~variable,
             scales = "free") +
  labs(x = "Valeur",
       y = "Nombre de communes",
       fill = "Commune")
```

Comme la distribution de `nb_obs` est très concentrée sur les petites valeurs, on peut la représenter en échalle log.

```{r, fig.cap = "Comparaison de la distribution du nombre d'observations (histogramme) entre les communes selon qu'elles sont écartées ou conservées."}
ggplot(data = comparaison_conservees_ecartees %>% filter(variable == "nb_obs"),
       aes(x = valeur,
           fill = ecartee)) +
  geom_histogram(alpha = 0.3,
                 col = "black") +
  scale_x_log10() +
  labs(x = "Nombre d'observations",
       y = "Nombre de communes",
       fill = "Commune")
```

Même type de graphique mais en densités. Comme la surface sous chaque courbe est 1, les communes écartées, moins nombreuses que celles qui sont conservées, apparaissent plus clairement.

```{r, fig.cap = "Comparaison de la distribution du nombre d'observations (diagramme de densité) entre les communes selon qu'elles sont écartées ou conservées."}
ggplot(data = comparaison_conservees_ecartees %>% filter(variable == "nb_obs"),
       aes(x = valeur,
           fill = ecartee)) +
  geom_density(alpha = 0.3,
                 col = "black") +
  scale_x_log10() +
  labs(x = "Nombre d'observations",
       y = "Nombre de communes",
       fill = "Commune")
```
